{
 "metadata": {
  "name": "",
  "signature": "sha256:34ec2a2159ae16d01658843266a2a545d4916f7b69762e8ea460bd3c9ffaa314"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###From a Twitter Username and publication titles, create a similarity measure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Example user:\n",
      "\n",
      "Paul Groth"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "username = 'pgroth'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Publication titles found through Google Scholar"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "publications_titles = json.load(open('paul_pubs.json'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import similarities, models, corpora, utils\n",
      "from nltk.corpus import stopwords\n",
      "stoplist = stopwords.words('english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "re_split = re.compile('\\W+')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read in all publications titles and tokenize them, also removing all stopwords and words that only occur once."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texts = [ [word for word in re.split(re_split,pub.lower()) if word not in stoplist and word != '']   for pub in publication_titles]\n",
      "all_tokens = sum(texts, [])\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once]   for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a dictionary based on these texts, a 'bag-of-words', where every token in the dictionary gets an id. Also an corpus based on this dictionary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(texts)\n",
      "dictionary.save('/tmp/paul.dict')\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create an Latent Similarity Indexing Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus, id2word = dictionary, num_topics=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this model we can create an similarity measure on new sentences, to which topic they belong. I hope we can also find a way to compare an entire twitter feed to this model, and say how similar it is to this corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = similarities.MatrixSimilarity(lsi[corpus])\n",
      "index.save('/tmp/paul.index')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec_bow = dictionary.doc2bow('New sentence containing the words Provenance Query experiments chemistry data'.lower().split())\n",
      "vec_lsi = lsi[vec_bow]\n",
      "sims = index[vec_lsi]\n",
      "sims = enumerate(sims)\n",
      "sims = sorted(sims, key=lambda item: -item[1])\n",
      "print sims"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(29, 0.98630798), (28, 0.9691515), (4, 0.93104374), (70, 0.90211278), (43, 0.77245337), (76, 0.76607108), (62, 0.76288593), (41, 0.73851448), (49, 0.73851448), (59, 0.73218888), (97, 0.72368819), (83, 0.70841205), (45, 0.70381987), (98, 0.69535011), (93, 0.69272143), (40, 0.69191432), (82, 0.68780637), (14, 0.68097329), (1, 0.67749143), (21, 0.65240085), (69, 0.65220439), (71, 0.64739621), (86, 0.64215934), (89, 0.63160402), (42, 0.63137156), (2, 0.62525499), (68, 0.61808687), (95, 0.61705238), (52, 0.60956055), (9, 0.60694212), (17, 0.59847367), (34, 0.59830147), (53, 0.5957135), (19, 0.59241885), (30, 0.59241885), (65, 0.59232157), (13, 0.59006155), (58, 0.58124965), (55, 0.5782932), (39, 0.57802844), (90, 0.56224394), (96, 0.5543443), (24, 0.53736526), (5, 0.53297108), (61, 0.53297108), (60, 0.53241158), (74, 0.51870018), (91, 0.51433152), (6, 0.50031388), (63, 0.49763128), (66, 0.4930937), (27, 0.49132413), (12, 0.48040721), (23, 0.4716045), (37, 0.44861746), (81, 0.43076739), (31, 0.42521673), (51, 0.38576302), (11, 0.38449615), (35, 0.37379849), (0, 0.36039618), (67, 0.33857304), (20, 0.33734435), (92, 0.33734435), (38, 0.3365238), (44, 0.26474395), (87, 0.25985718), (25, 0.17381135), (99, 0.15976539), (77, 0.1567848), (79, 0.1547946), (80, 0.14281552), (73, 0.13931268), (72, 0.12244276), (85, 0.10450181), (26, 0.10249986), (36, 0.061227877), (3, 0.057882704), (57, 0.052549478), (22, 0.044505171), (64, 0.043574587), (75, 0.037561137), (18, 0.0069109146), (32, 0.0023760106), (48, 0.0020793215), (7, 0.0), (78, 0.0), (15, -0.0019571483), (84, -0.010152709), (56, -0.010488324), (46, -0.015355438), (10, -0.021925382), (94, -0.03057088), (88, -0.054789431), (16, -0.055076569), (47, -0.055378556), (50, -0.070549972), (8, -0.099939071), (33, -0.099939071), (54, -0.13369395)]\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}